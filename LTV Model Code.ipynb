{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad6fbbe5-b80f-46aa-b03e-8c7b851a06d4",
   "metadata": {},
   "source": [
    "# PROJECT SCOPE\n",
    "\n",
    "The scope of this project in this code base is to build a life time value of a customer to enable businesses know and understand their customers and how much they bring throughout their life time (with the business); here, we will be using the bank churn data, and for this model, we will be focusing on companies in the financial services sector. for this and the remaining model, we will be using the BankChurners.csv file saved in the Datasets folder. However after the model is runned it saved the processed data into its own folder saved in the Dataset folder where it has the data with the LTV prediction generated based off this model\n",
    "\n",
    "Lifetime Value or LTV is an estimate of the average revenue that a customer will generate throughout their lifespan as a customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fad155-c62b-4d1c-bd9d-a3b41240e9da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e731d5e-5367-470c-a84c-c19cd4685a3b",
   "metadata": {},
   "source": [
    "# IMPORTING NECCESSARY PACKAGES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb9a07b7-49dd-4916-87e6-e4bf6110f6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a5fc10-c9bb-4feb-a695-c51735748607",
   "metadata": {},
   "source": [
    "# LOADING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "425de162-6f83-4e30-be39-0c0c876c4088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Ingestion\n",
    "file_path = r'/Users/abduljalaalabubakar/Desktop/Projects/Symply Finance/Customer Insight Model/Fintech Customer Insight Model/Datasets/Bank Churn Dataset/BankChurners.csv'\n",
    "data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24efdf9f-6b12-4ee0-a7ab-b743ba5e3c0d",
   "metadata": {},
   "source": [
    "# DATA INVESTIGATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74fc0f6a-9174-48b4-8d6b-2374d44f33fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values:\n",
      " CLIENTNUM                                                                                                                             0\n",
      "Attrition_Flag                                                                                                                        0\n",
      "Customer_Age                                                                                                                          0\n",
      "Gender                                                                                                                                0\n",
      "Dependent_count                                                                                                                       0\n",
      "Education_Level                                                                                                                       0\n",
      "Marital_Status                                                                                                                        0\n",
      "Income_Category                                                                                                                       0\n",
      "Card_Category                                                                                                                         0\n",
      "Months_on_book                                                                                                                        0\n",
      "Total_Relationship_Count                                                                                                              0\n",
      "Months_Inactive_12_mon                                                                                                                0\n",
      "Contacts_Count_12_mon                                                                                                                 0\n",
      "Credit_Limit                                                                                                                          0\n",
      "Total_Revolving_Bal                                                                                                                   0\n",
      "Avg_Open_To_Buy                                                                                                                       0\n",
      "Total_Amt_Chng_Q4_Q1                                                                                                                  0\n",
      "Total_Trans_Amt                                                                                                                       0\n",
      "Total_Trans_Ct                                                                                                                        0\n",
      "Total_Ct_Chng_Q4_Q1                                                                                                                   0\n",
      "Avg_Utilization_Ratio                                                                                                                 0\n",
      "Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1    0\n",
      "Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2    0\n",
      "dtype: int64\n",
      "\n",
      "Class Distribution (%):\n",
      " Attrition_Flag\n",
      "Existing Customer    83.934038\n",
      "Attrited Customer    16.065962\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Data Investigation\n",
    "print(\"Missing Values:\\n\", data.isnull().sum())\n",
    "print(\"\\nClass Distribution (%):\\n\", data['Attrition_Flag'].value_counts(normalize=True) * 100)\n",
    "\n",
    "# Dropping unnecessary columns and handle missing values\n",
    "data.dropna(inplace=True)\n",
    "data = data.drop(['CLIENTNUM'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb2e593-b4f9-447b-82e8-a81b392b8759",
   "metadata": {},
   "source": [
    "# DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e695f20-73da-4f84-b1ea-0317ac04aa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the categorical variables\n",
    "label_encoders = {}\n",
    "for column in data.select_dtypes(include=['object']).columns:\n",
    "    le = LabelEncoder()\n",
    "    data[column] = le.fit_transform(data[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "#  Defining the LTV Target Variable\n",
    "# Using Total_Trans_Amt, Avg_Utilization_Ratio, and retention time (Months_on_book)\n",
    "data['LTV'] = data['Total_Trans_Amt'] * data['Avg_Utilization_Ratio'] * data['Months_on_book']\n",
    "\n",
    "# Data Preprocessing\n",
    "X = data.drop(['LTV'], axis=1)  # Features\n",
    "y = data['LTV']  # Target\n",
    "\n",
    "# Standardizing the numerical features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Model Selection\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(),\n",
    "    \"Gradient Boosting Regressor\": GradientBoostingRegressor(),\n",
    "    \"Neural Network Regressor\": MLPRegressor(max_iter=300)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9588439-5a9d-478f-a2c9-98a8ff839344",
   "metadata": {},
   "source": [
    "# DATA TRAINING AND SAVING THE BEST MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45010a0b-c73b-409a-8e8b-e9cb7fbf4dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Linear Regression...\n",
      "Training Random Forest Regressor...\n",
      "Training Gradient Boosting Regressor...\n",
      "Training Neural Network Regressor...\n"
     ]
    }
   ],
   "source": [
    "# Defining the folders to store results\n",
    "model_folder_path = r'/Users/abduljalaalabubakar/Desktop/Projects/Symply Finance/Customer Insight Model/Fintech Customer Insight Model/Customer_LTV_Best_Models'\n",
    "results_folder_path = r'/Users/abduljalaalabubakar/Desktop/Projects/Symply Finance/Customer Insight Model/Fintech Customer Insight Model/Datasets/Customer_LTV_Results'\n",
    "os.makedirs(model_folder_path, exist_ok=True)\n",
    "os.makedirs(results_folder_path, exist_ok=True)\n",
    "\n",
    "# Training and Evaluating Models\n",
    "results = {}\n",
    "best_model = None\n",
    "best_score = float('-inf')\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Saving the results\n",
    "    results[name] = {\n",
    "        \"Mean Absolute Error\": mae,\n",
    "        \"R-squared\": r2\n",
    "    }\n",
    "    \n",
    "    # Saving the best model\n",
    "    if r2 > best_score:\n",
    "        best_score = r2\n",
    "        best_model = model\n",
    "\n",
    "# Saving the best model\n",
    "best_model_path = os.path.join(model_folder_path, \"best_ltv_model.pkl\")\n",
    "joblib.dump(best_model, best_model_path)\n",
    "print(f\"\\nBest model saved to: {best_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6117d9ea-4911-47d2-b41a-fc6e228bc974",
   "metadata": {},
   "source": [
    "# DISPLAYING THE RESULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6fbe7f-8a71-4e31-95ea-2d94dbeacdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating the predictions using the best model on the entire dataset\n",
    "ltv_predictions = best_model.predict(X_scaled)\n",
    "\n",
    "# Saving the predictions to a new column in the original data\n",
    "data['Predicted_LTV'] = ltv_predictions\n",
    "\n",
    "# Saving the dataset with LTV predictions to a new file\n",
    "output_file_path = os.path.join(results_folder_path, \"BankChurners_with_LTV.csv\")\n",
    "data.to_csv(output_file_path, index=False)\n",
    "print(f\"\\nLTV predictions saved to: {output_file_path}\")\n",
    "\n",
    "# Displaying the results\n",
    "print(\"\\n### Model Evaluation Results ###\")\n",
    "for name, metrics in results.items():\n",
    "    print(f\"\\nModel: {name}\")\n",
    "    print(f\"Mean Absolute Error: {metrics['Mean Absolute Error']}\")\n",
    "    print(f\"R-squared (R²): {metrics['R-squared']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c5c223-03ed-4844-a76f-dae470812b44",
   "metadata": {},
   "source": [
    "# Next Steps for Customer LTV Model Implementation\n",
    "1. Model Deployment\n",
    "Package the Random Forest Regressor:\n",
    "Export the model using joblib.\n",
    "Prepare an API using frameworks like Flask or FastAPI to allow real-time or batch predictions.\n",
    "Set up a Scalable Pipeline:\n",
    "Build a data pipeline to handle preprocessing (e.g., encoding, scaling) for incoming customer data.\n",
    "Include functionality to handle missing or erroneous data.\n",
    "2. Integrate with Business Systems\n",
    "CRM Integration:\n",
    "Connect the LTV prediction model to CRM systems to provide actionable insights for marketing and customer retention teams.\n",
    "Dashboard Development:\n",
    "Create dashboards for business users to view LTV predictions and associated feature insights.\n",
    "3. Model Monitoring and Maintenance\n",
    "Performance Monitoring:\n",
    "Track metrics like MAE, R², and drift detection in real-time.\n",
    "Retraining Strategy:\n",
    "Set up automated or periodic retraining pipelines to update the model with the latest data.\n",
    "Error Logging:\n",
    "Implement logging to capture and address prediction errors.\n",
    "4. Data Enrichment and Feature Engineering\n",
    "Incorporate External Data:\n",
    "Explore adding external variables (e.g., macroeconomic factors, market trends).\n",
    "Analyze Feature Contributions:\n",
    "Use tools like permutation importance to validate the impact of features on LTV predictions.\n",
    "Dynamic Features:\n",
    "Create time-based features to capture trends (e.g., recent transaction frequency).\n",
    "5. Customer Segmentation and Targeting\n",
    "Segment Customers:\n",
    "Use LTV predictions to group customers into tiers (e.g., high, medium, low).\n",
    "Retention Campaigns:\n",
    "Develop targeted retention strategies for customers with declining LTV.\n",
    "Upselling Opportunities:\n",
    "Focus premium products or services on high-LTV customers.\n",
    "6. Scale for Production\n",
    "Distributed Processing:\n",
    "Implement distributed frameworks (e.g., Apache Spark) to handle larger datasets.\n",
    "Cloud Integration:\n",
    "Deploy the pipeline and model on cloud platforms (e.g., AWS, Azure) for scalability and reliability.\n",
    "7. Validate Model Performance in a Live Environment\n",
    "Pilot Testing:\n",
    "Roll out the LTV model to a small segment of customers.\n",
    "Measure impact on business KPIs like retention rate, upsell success, and campaign ROI.\n",
    "A/B Testing:\n",
    "Compare model-driven strategies against traditional approaches to validate effectiveness.\n",
    "8. Reporting and Documentation\n",
    "Create Reports:\n",
    "Summarize model predictions, accuracy metrics, and customer insights for stakeholders.\n",
    "Maintain Documentation:\n",
    "Document preprocessing steps, model assumptions, and API endpoints for developers and business users.\n",
    "9. Iterate and Improve\n",
    "Feedback Loops:\n",
    "Gather feedback from users to refine the model and dashboard.\n",
    "Hyperparameter Tuning:\n",
    "Explore optimization of model parameters for better performance.\n",
    "Incorporate Additional Use Cases:\n",
    "Extend the pipeline to include related use cases like churn prediction or cross-sell propensity."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
